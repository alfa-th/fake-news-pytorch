{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\r\n",
    "\r\n",
    "import torch \r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "\r\n",
    "from torchtext.data.utils import get_tokenizer\r\n",
    "from torchtext.vocab import build_vocab_from_iterator\r\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "\r\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "(test_ratio, valid_ratio) = (0.80, 0.80)\r\n",
    "device = torch.device(\"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df_raw = pd.read_csv(\"../common-data/fake-news/news.csv\")\r\n",
    "\r\n",
    "df_raw[\"label\"] = (df_raw[\"label\"] == \"FAKE\").astype(\"int\")\r\n",
    "df_raw[\"titletext\"] = df_raw[\"title\"] + \". \" + df_raw[\"text\"]\r\n",
    "df_raw = df_raw.reindex(columns=[\"label\", \"title\", \"text\", \"titletext\"])\r\n",
    "\r\n",
    "df_raw.drop(df_raw[df_raw.text.str.len() < 5].index, inplace=True)\r\n",
    "\r\n",
    "def trim_string(x):\r\n",
    "  x = x.split(maxsplit=200)\r\n",
    "  x = \" \".join(x[:200])\r\n",
    "  return x\r\n",
    "\r\n",
    "df_raw[\"text\"] = df_raw[\"text\"].apply(trim_string)\r\n",
    "df_raw[\"titletext\"] = df_raw[\"titletext\"].apply(trim_string)\r\n",
    "\r\n",
    "df_real = df_raw[df_raw[\"label\"] == 0]\r\n",
    "df_fake = df_raw[df_raw[\"label\"] == 1]\r\n",
    "\r\n",
    "df_real_trainvalid, df_real_test = train_test_split(df_real, train_size=test_ratio, random_state=1)\r\n",
    "df_fake_trainvalid, df_fake_test = train_test_split(df_fake, train_size=test_ratio, random_state=1)\r\n",
    "\r\n",
    "df_real_train, df_real_valid = train_test_split(df_real_trainvalid, train_size=valid_ratio, random_state=1)\r\n",
    "df_fake_train, df_fake_valid = train_test_split(df_fake_trainvalid, train_size=valid_ratio, random_state=1)\r\n",
    "\r\n",
    "df_train = pd.concat([df_real_train, df_fake_train], ignore_index=True, sort=False)\r\n",
    "df_valid = pd.concat([df_real_valid, df_fake_valid], ignore_index=True, sort=False)\r\n",
    "df_test = pd.concat([df_real_test, df_fake_test], ignore_index=True, sort=False)\r\n",
    "\r\n",
    "df_train.to_csv(\"../common-data/fake-news/news_train.csv\", index=False)\r\n",
    "df_valid.to_csv(\"../common-data/fake-news/news_valid.csv\", index=False)\r\n",
    "df_test.to_csv(\"../common-data/fake-news/news_test.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df_train = pd.read_csv(\"../common-data/fake-news/news_train.csv\")\r\n",
    "df_valid = pd.read_csv(\"../common-data/fake-news/news_valid.csv\")\r\n",
    "df_test = pd.read_csv(\"../common-data/fake-news/news_test.csv\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\r\n",
    "\r\n",
    "def yield_tokens(df_data):\r\n",
    "  for text in tqdm(df_data[\"titletext\"]):\r\n",
    "    yield tokenizer(text)\r\n",
    "\r\n",
    "vocab = build_vocab_from_iterator(yield_tokens(df_train), specials=[\"<unk>\"])\r\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\r\n",
    "len(vocab)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 4029/4029 [00:01<00:00, 3623.11it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "39226"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def text_pipeline(text):\r\n",
    "  return vocab(tokenizer(text))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "df_test = df_train.copy()\r\n",
    "# df_test = df_test[[\"label\", \"titletext\"]]\r\n",
    "# df_test[\"titletext\"] = df_test[\"titletext\"].apply(text_pipeline).apply(torch.tensor)\r\n",
    "# df_test[\"label\"] = df_test[\"label\"].apply(torch.tensor)\r\n",
    "df_test[\"titletext_len\"] = df_test[\"titletext\"].apply(text_pipeline).apply(len)\r\n",
    "df_test[\"titletext_len\"].max()\r\n",
    "# list(df_test.to_records(index=False))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "487"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def collate_batch(batch):\r\n",
    "  label_list, titletext_list, titletext_len_list = [], [], []\r\n",
    "\r\n",
    "  for _label, _titletext in batch:\r\n",
    "    label_list.append(_label)\r\n",
    "    _titletext = text_pipeline(_titletext)\r\n",
    "    _titletext = torch.tensor(_titletext, dtype=torch.int64)\r\n",
    "    titletext_list.append(_titletext)\r\n",
    "    titletext_len_list.append(len(_titletext))\r\n",
    "\r\n",
    "  label_list = torch.tensor(label_list, dtype=torch.float32)\r\n",
    "  titletext_list = pad_sequence(\r\n",
    "      titletext_list, batch_first=True)\r\n",
    "  titletext_len_list = torch.tensor(titletext_len_list, dtype=torch.int64)\r\n",
    "\r\n",
    "  return label_list.to(device), titletext_list.to(device), titletext_len_list.to(device)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def df_to_dataset(df):\r\n",
    "  df = df.copy()\r\n",
    "  df = df[[\"label\", \"titletext\"]]\r\n",
    "\r\n",
    "  return list(df.to_records(index=False))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "BS = 32\r\n",
    "\r\n",
    "train_iter = DataLoader(df_to_dataset(\r\n",
    "    df_train), batch_size=BS, shuffle=True, collate_fn=collate_batch)\r\n",
    "valid_iter = DataLoader(df_to_dataset(\r\n",
    "    df_valid), batch_size=BS, shuffle=True, collate_fn=collate_batch)\r\n",
    "test_iter = DataLoader(df_to_dataset(\r\n",
    "    df_test), batch_size=BS, shuffle=True, collate_fn=collate_batch)\r\n",
    "\r\n",
    "for labels, titletext, titletext_len in train_iter:\r\n",
    "  print(labels, titletext, titletext_len); assert False"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-34ab2a2a244f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     df_test), batch_size=BS, shuffle=True, collate_fn=collate_batch)\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitletext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitletext_len\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitletext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitletext_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[1;32massert\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-5a5a6d797618>\u001b[0m in \u001b[0;36mcollate_batch\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     14\u001b[0m   \u001b[0mtitletext_len_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitletext_len_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitletext_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitletext_len_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "class LSTM(nn.Module): \r\n",
    "  def __init__(self, vocab, hidden_dim=128, embed_dim=300):\r\n",
    "    super(LSTM, self).__init__()\r\n",
    "\r\n",
    "    self.hidden_dim = hidden_dim\r\n",
    "    \r\n",
    "    self.embedding = nn.Embedding(len(vocab), embed_dim)\r\n",
    "    self.lstm = nn.LSTM(\r\n",
    "      input_size=embed_dim,\r\n",
    "      hidden_size=hidden_dim,\r\n",
    "      num_layers=1,\r\n",
    "      batch_first=True,\r\n",
    "      bidirectional=True\r\n",
    "    )\r\n",
    "    self.drop = nn.Dropout(p=0.5)\r\n",
    "    self.fc = nn.Linear(2 * hidden_dim, 1)\r\n",
    "  \r\n",
    "  def forward(self, text, text_len):\r\n",
    "    # print(text.size())\r\n",
    "    # print(text_len.size())\r\n",
    "    text_emb = self.embedding(text)\r\n",
    "\r\n",
    "    # print(text_emb.size())\r\n",
    "    packed_input = pack_padded_sequence(text_emb, text_len, batch_first=True, enforce_sorted=False)\r\n",
    "    packed_output, _ = self.lstm(packed_input)\r\n",
    "    output, _ = pad_packed_sequence(packed_output, batch_first=True)\r\n",
    "    # print(output.size(), \"sneed\")\r\n",
    "\r\n",
    "    out_forward = output[range(len(output)), text_len - 1, :self.hidden_dim]\r\n",
    "    # print(out_forward.size())\r\n",
    "    out_reverse = output[:, 0, self.hidden_dim:]\r\n",
    "    # print(out_reverse.size())\r\n",
    "    out_reduced = torch.cat((out_forward, out_reverse), 1)\r\n",
    "    # print(out_reduced.size()); assert False\r\n",
    "\r\n",
    "    text_feats = self.drop(out_reduced)\r\n",
    "    text_feats = self.fc(text_feats)\r\n",
    "    text_feats = torch.squeeze(text_feats, 1)\r\n",
    "    \r\n",
    "    preds = torch.sigmoid(text_feats)\r\n",
    "    \r\n",
    "    return preds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def train(\r\n",
    "    model,\r\n",
    "    optimizer,\r\n",
    "    criterion=nn.BCELoss(),\r\n",
    "    train_loader=train_iter,\r\n",
    "    valid_loader=valid_iter,\r\n",
    "    num_epochs=5,\r\n",
    "    eval_every=5,\r\n",
    "):\r\n",
    "  run_loss = 0.0\r\n",
    "  valid_run_loss = 0.0\r\n",
    "  global_step = 0\r\n",
    "  train_loss_list = []\r\n",
    "  valid_loss_list = []\r\n",
    "  global_step_list = []\r\n",
    "  ave_train_loss = None\r\n",
    "  ave_valid_loss = None\r\n",
    "\r\n",
    "  model.train()\r\n",
    "  for epoch in range(num_epochs):\r\n",
    "    with tqdm(train_loader, unit=\"batch\") as tbatch:\r\n",
    "      for labels, titletext, titletext_len in tbatch:\r\n",
    "        tbatch.set_description(f\"Epoch {epoch}\")\r\n",
    "\r\n",
    "        output = model(titletext, titletext_len)\r\n",
    "        loss = criterion(output, labels)\r\n",
    "\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        run_loss += loss.item()\r\n",
    "        global_step += 1\r\n",
    "\r\n",
    "        tbatch.set_postfix(step=f\"{ global_step }/{(num_epochs * len(train_loader)) }\",\r\n",
    "                           train_loss=ave_train_loss,\r\n",
    "                           valid_loss=ave_valid_loss)\r\n",
    "\r\n",
    "        if global_step % eval_every == 0:\r\n",
    "          model.eval()\r\n",
    "          with torch.no_grad():\r\n",
    "            for labels, titletext, titletext_len in valid_loader:\r\n",
    "              labels = labels.to(device)\r\n",
    "              titletext = titletext.to(device)\r\n",
    "              titletext_len = titletext_len.to(device)\r\n",
    "\r\n",
    "              output = model(titletext, titletext_len)\r\n",
    "              loss = criterion(output, labels)\r\n",
    "\r\n",
    "              valid_run_loss += loss.item()\r\n",
    "\r\n",
    "          ave_train_loss = run_loss / eval_every\r\n",
    "          ave_valid_loss = run_loss / len(valid_loader)\r\n",
    "          train_loss_list.append(ave_train_loss)\r\n",
    "          valid_loss_list.append(ave_valid_loss)\r\n",
    "          global_step_list.append(global_step)\r\n",
    "\r\n",
    "          run_loss, valid_run_loss = 0.0, 0.0\r\n",
    "\r\n",
    "          model.train()\r\n",
    "          tbatch.set_postfix(step=f\"{ global_step }/{(num_epochs * len(train_loader)) }\",\r\n",
    "                             train_loss=loss.item(),\r\n",
    "                             valid_loss=ave_valid_loss)\r\n",
    "\r\n",
    "  print(\"Finished training\")\r\n",
    "\r\n",
    "\r\n",
    "model = LSTM(vocab=vocab).to(device)\r\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\r\n",
    "\r\n",
    "train(model=model, optimizer=optimizer, num_epochs=10)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 0:   5%|▍         | 6/126 [01:24<28:11, 14.10s/batch, step=6/1260, train_loss=0.681, valid_loss=0.106]"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "state_dict = {\r\n",
    "  \"model_state_dict\": model.state_dict(),\r\n",
    "  \"optimizer_state_dict\": optimizer.state_dict(),\r\n",
    "}\r\n",
    "\r\n",
    "torch.save(state_dict, \"../common-data/fake-news/\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit"
  },
  "interpreter": {
   "hash": "b21f954a467df7c68612b09bb9acf4e7c404e490bba3fc0474b60a91347c9dbb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}